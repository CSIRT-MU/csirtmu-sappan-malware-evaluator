import base64
from datetime import datetime

from airflow.decorators import dag, task
from airflow.operators.python import get_current_context
from airflow.operators.python import BranchPythonOperator
from airflow.utils.trigger_rule import TriggerRule
from airflow.hooks.S3_hook import S3Hook

from airflow.providers.amazon.aws.operators.s3_copy_object import S3CopyObjectOperator
from airflow.providers.amazon.aws.operators.s3_delete_objects import S3DeleteObjectsOperator

from operators.observable_evaluator.observable_evaluator_analyse_files_operator import ObservableEvaluatorAnalyseFilesOperator
from operators.blocker.ip_blocker_trigger_multiple_operator import IPBlockerTriggerMultipleOperator
from operators.dnsrpz.dnsrpz_trigger_multiple_operator import DNSRPZTriggerMultipleOperator
from operators.reporters.create_pdf_report_operator import CreatePDFReportOperator
from operators.misp.misp_create_malware_event_operator import MISPCreateMalwareEventOperator
from operators.netflow.netflow_ip_communicators_operator import NetflowCommunicatingIPsOperator


from tempfile import NamedTemporaryFile

MINIO_CONN_ID = 's3_conn_id'
S3_BUCKET_MALWARE = 'csirt-mu-malware'
S3_BUCKET_PROCESSING = 'csirt-mu-malware-processed'
S3_BUCKET_REPORTS = 'csirt-mu-reports'
INTELOWL_CONN_ID = 'intelowl_conn_id'
OBSERVABLE_EVALUATOR = 'observable_evaluator_conn_id'
MISP_CONN_ID = 'misp_local_conn_id'


docs = """
# Malware pipeline
 This DAG represents a playbook responsible for handling potential malware file.

Input format:

```
{
    "s3" : bool,
    "file_name" : str
    "file" : OPTIONAL (only if s3 is false) - file encoded in B64
}
```
"""


@dag(
    default_args={
        'owner': 'airflow',
        'start_date': datetime.fromtimestamp(0),
        'depends_on_past': False,
        'retries': 2,
    },
    description='Malware - pipeline automatic handling',
    schedule_interval=None,
    doc_md=docs
    #    on_success_callback=cleanup_xcom,
)
def malware_dag():
    @task(multiple_outputs=True)
    def parse_params():
        dag_params = get_current_context()["dag_run"].conf
        params = {}

        params["s3"] = dag_params.get("s3", False)
        if params["s3"]:
            if "file_name" not in dag_params.keys():
                raise ValueError("Missing file name!")
            params["file_name"] = dag_params["file_name"]
        else:
            if "file_name" not in dag_params.keys():
                raise ValueError("Missing file name!")
            params["file_name"] = dag_params["file_name"]
            if "file" not in dag_params.keys():
                raise ValueError("Missing file!")
            params["file"] = dag_params["file"]

        return params

    params = parse_params()

    pick_path = BranchPythonOperator(
        task_id='pick_s3_path',
        python_callable=lambda s3:
        ['copy_file_to_processing_bucket']
        if s3
        else ['upload_file_to_processing_bucket'],
        op_kwargs={'s3': params['s3']}
    )

    copy_objects = S3CopyObjectOperator(
        task_id='copy_file_to_processing_bucket',
        source_bucket_name=S3_BUCKET_MALWARE,
        dest_bucket_name=S3_BUCKET_PROCESSING,
        source_bucket_key=params["file_name"],
        dest_bucket_key=params["file_name"],
        aws_conn_id=MINIO_CONN_ID,
    )
  # CLEANUP
    delete_objects = S3DeleteObjectsOperator(
        task_id='delete_analyzed_files',
        bucket=S3_BUCKET_MALWARE,
        keys=params["file_name"],
        aws_conn_id=MINIO_CONN_ID
    )

    @task
    def upload_file_to_processing_bucket(key, content, bucket=S3_BUCKET_PROCESSING, s3_conn_id=MINIO_CONN_ID):
        client = S3Hook(s3_conn_id).get_conn()
        with NamedTemporaryFile("w+b") as f:
            try:
                content = base64.b64decode(content)
            except:
                print("Not B64, writing as it is")
            f.write(content)
            f.seek(0, 0)
            client.upload_fileobj(f.file, bucket, key)

  # RUN OBSERVABLE EVALUATOR FROM S3
    run_analysis = ObservableEvaluatorAnalyseFilesOperator(
        task_id="run_analysis",
        file_key=params["file_name"],
        conn_id=OBSERVABLE_EVALUATOR,
        s3_conn_id=MINIO_CONN_ID,
        bucket=S3_BUCKET_PROCESSING,
        trigger_rule=TriggerRule.NONE_FAILED
    )

    pick_path >> upload_file_to_processing_bucket(
        params['file_name'], params['file']) >> run_analysis

    pick_path >> copy_objects >> [delete_objects, run_analysis]

########## STANDARD BLOCKING PROCEDURE ##########################
    @ task(multiple_outputs=True)
    def prepare_blocking_information(analysis_result, file):
        observables = analysis_result['observables']
        block_params = {
            "ips": {"ips": []},
            "urls": {"urls": []},
            "domains": {"domains": []}
        }

        def create_record(value, toolname, type): return block_params[f"{type}s"][f"{type}s"].append(
            {
                type: value,
                "reason": f"Discovered in malware {file} by {', '.join(toolname)}",
                "length": 7
            }
        )

        for observable in observables.values():
            if observable['malicious']:
                create_record(
                    observable['observable'], observable['detected'], observable['observable_type'])
        return block_params

    block_params = prepare_blocking_information(
        run_analysis.output, params['file_name'])

    trigger_domain_blocking = DNSRPZTriggerMultipleOperator(
        task_id='trigger_dnsrpz_dag',
        data=block_params['domains'],
    )

# 4b) BLOCK IP
    trigger_ip_blocking = IPBlockerTriggerMultipleOperator(
        task_id='trigger_ip_blocker',
        data=block_params['ips']
    )
    
    [trigger_domain_blocking, trigger_ip_blocking]
    
## Find communicating IPs in netflow

    find_communicating_ips = NetflowCommunicatingIPsOperator(
        task_id='find_communicating_ips_in_netflow',
        data=run_analysis.output
    )
    
#### CREATE REPORT ####

    create_pdf_report = CreatePDFReportOperator(
        task_id='create_pdf_report',
        data=run_analysis.output,
        netflow_data=find_communicating_ips.output,
        bucket=S3_BUCKET_REPORTS,
        s3_conn_id=MINIO_CONN_ID
    )

    create_misp_event = MISPCreateMalwareEventOperator(
        task_id='create_misp_event',
        data=run_analysis.output,
        netflow_data=find_communicating_ips.output,
        conn_id=MISP_CONN_ID
    )


dag = malware_dag()
